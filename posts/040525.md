---
title: "Prompt Engineering"
tags: "llms"
date: "May 04, 2025"
---

# What's prompt?

Prompt is any interaction between you and LLM (Large Language Model)

- The message you sent to ChatGPT
- Content when you send a request to LLM API
- or the text message you sent to image/music generation models.

The reality is, output from LLM is as good as your prompt. That's why we need to create better prompts to get better results in any field â€“ concise, clean and structured prompts lead to more successful outcomes.

# Always clean and concise. 

Just like we get better results when we clearly explain a task to an intern, we should think of AI as an intern too. (Yes, AI is a powerful tool, but when we interact with it, we need to explain it like it's 5!)

# Examples and references

OpenAI discovered the same thing 5 years ago. ("Language Models are Few-Shot Learners"). There was only GPT-3 back in the time, and its performance not that good. But, prompt with examples was really common. template was Q A Q A. Nowadays probably all AI product has examples in the prompt. Write at least 1 example!

![from Twitter, Aravind Putrevu](/images/prompt-ex.jpeg)

# If task is hard, step by step.

Especially the problems in math or physics needs you to solve it in a step-by-step process. As we can't solve these kind of problems instantly, we can't expect AI to do so either. Plus, AI is an energy-intensive model (due to GPUs and architecture), so expecting it to solve a complex task in one go isn't realistic.

Only adding (Think step by step), improves the results. Also explaining how model should reason, like giving a direction will drive model to solve it in right way.

# Role and task info

In specific topics, we need to define the role of the AI! Ex: When you give a task in law, you should say "You're a lawyer, respond based on that."

In this way, model focuses only on that topic in semantic space. This is where using system prompts can be extremely beneficial.

# XML XML XML 

Add XML tags whenever you add content, or any info, it's like structuring the prompt. For example, we could wrap company information in `<company></company>` tags or request a json-formatted response by defining a structure like `{answer: <your answer>}`. When you use XML tags, don't forget to explain it in the prompt, like I'm going to use <company> tags.

# prefill

Some models accepts prefill for the answer. You can push the LLM to answer in your way. If you want json format, you can say start with `{"answer":`, and increase the accuracy + reliability.

# divide and conquer an LLM!

For tasks requiring multiple prompts, such as question-generation pipelines, we often get better results by sending several prompts in sequence:

1. A prompt that generates the question.
2. A prompt that checks if the question is correctly formatted and gives feedback.
3. A prompt that refines the question based on that feedback.

> Trying to do all of this in a single prompt will cause hallucinations and errors, whereas a chained approach gives more reliable outcomes.

Leaked prompts: [link](https://github.com/jujumilk3/leaked-system-prompts)
